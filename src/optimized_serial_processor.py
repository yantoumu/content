#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„ä¸²è¡Œæ‰¹æ¬¡å¤„ç†å™¨
åŸºäºæµ‹è¯•ç»“æœå®ç°çš„é«˜æ€§èƒ½ä¸²è¡Œå¤„ç†æ–¹æ¡ˆ
"""

import time
import logging
import requests
import queue
import threading
from typing import Dict, List, Any, Optional
from src.config import config
from src.keyword_api import KeywordAPI
from src.api_health_monitor import api_health_monitor

logger = logging.getLogger(__name__)

class OptimizedSerialProcessor:
    """ä¼˜åŒ–çš„ä¸²è¡Œæ‰¹æ¬¡å¤„ç†å™¨
    
    åŸºäºæ€§èƒ½æµ‹è¯•ç»“æœï¼Œå®ç°æœ€ä½³çš„ä¸²è¡Œå¤„ç†ç­–ç•¥ï¼š
    - è¿æ¥æ± å¤ç”¨
    - æ™ºèƒ½é—´éš”æ§åˆ¶
    - åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´
    - å¼‚æ­¥é˜Ÿåˆ—ç¼“å†²
    """
    
    def __init__(self, api_urls: List[str], batch_size: int = 5, batch_interval: float = 2.0):
        self.api_urls = api_urls
        self.batch_size = batch_size
        self.batch_interval = batch_interval
        self.logger = logger
        
        # åˆ›å»ºä¼˜åŒ–çš„APIå®¢æˆ·ç«¯
        self.api_client = None
        self._init_api_client()

        # å¼‚æ­¥é˜Ÿåˆ—ç¼“å†²
        self.request_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.processing_thread = None
        self.is_running = False

    def _init_api_client(self):
        """åˆå§‹åŒ–ä¼˜åŒ–çš„APIå®¢æˆ·ç«¯"""
        if self.api_urls:
            self.api_client = KeywordAPI(
                api_urls=self.api_urls,
                timeout=getattr(config, 'keyword_query_timeout', 80),
                max_retries=getattr(config, 'api_retry_max', 2)
            )
            
            # å¯ç”¨è¿æ¥æ± ä¼˜åŒ–
            if hasattr(self.api_client, 'session'):
                self.api_client.session.headers.update({
                    'Connection': 'keep-alive',
                    'Keep-Alive': 'timeout=30, max=100'
                })
                
                # é…ç½®è¿æ¥æ± 
                adapter = requests.adapters.HTTPAdapter(
                    pool_connections=1,
                    pool_maxsize=10,
                    max_retries=0  # æˆ‘ä»¬è‡ªå·±å¤„ç†é‡è¯•
                )
                self.api_client.session.mount('http://', adapter)
                self.api_client.session.mount('https://', adapter)
    
    def process_keywords_optimized(self, keywords: List[str]) -> Dict[str, Any]:
        """ä¼˜åŒ–çš„ä¸²è¡Œå…³é”®è¯å¤„ç†"""
        self.logger.info(f"ğŸš€ å¼€å§‹ä¼˜åŒ–ä¸²è¡Œå¤„ç† {len(keywords)} ä¸ªå…³é”®è¯")
        
        if not keywords:
            return {}
        
        # åˆ›å»ºæ‰¹æ¬¡
        batches = self._create_adaptive_batches(keywords)
        results = {}
        
        start_time = time.time()
        
        # ä¸²è¡Œå¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        for i, batch in enumerate(batches, 1):
            self.logger.info(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i}/{len(batches)} ({len(batch)} ä¸ªå…³é”®è¯)")
            
            batch_start = time.time()
            
            # å¤„ç†å•ä¸ªæ‰¹æ¬¡
            batch_result = self._process_single_batch_optimized(batch)
            if batch_result:
                results.update(batch_result)
            
            batch_time = time.time() - batch_start
            success_count = len(batch_result) if batch_result else 0
            
            self.logger.info(f"  âœ… æ‰¹æ¬¡ {i} å®Œæˆï¼Œè€—æ—¶ {batch_time:.2f}sï¼ŒæˆåŠŸ {success_count}/{len(batch)} ä¸ª")
            
            # æ™ºèƒ½é—´éš”æ§åˆ¶ï¼ˆé™¤äº†æœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼‰
            if i < len(batches):
                wait_time = self._calculate_optimal_wait_time(batch_time)
                if wait_time > 0:
                    self.logger.debug(f"  â±ï¸  æ™ºèƒ½ç­‰å¾… {wait_time:.2f}s")
                    time.sleep(wait_time)
        
        total_time = time.time() - start_time
        success_rate = (len(results) / len(keywords)) * 100
        
        self.logger.info(f"ğŸ¯ ä¼˜åŒ–ä¸²è¡Œå¤„ç†å®Œæˆ:")
        self.logger.info(f"  - æ€»è€—æ—¶: {total_time:.2f}s")
        self.logger.info(f"  - æˆåŠŸç‡: {success_rate:.1f}% ({len(results)}/{len(keywords)})")
        self.logger.info(f"  - å¹³å‡æ¯ä¸ªå…³é”®è¯: {total_time/len(keywords):.2f}s")
        self.logger.info(f"  - å¤„ç†é€Ÿåº¦: {len(keywords)/total_time:.2f} å…³é”®è¯/ç§’")
        
        return {
            'results': results,
            'total_time': total_time,
            'success_rate': success_rate,
            'avg_time_per_keyword': total_time / len(keywords),
            'throughput': len(keywords) / total_time
        }
    
    def _create_adaptive_batches(self, keywords: List[str]) -> List[List[str]]:
        """åˆ›å»ºè‡ªé€‚åº”æ‰¹æ¬¡"""
        batches = []
        
        # æ ¹æ®APIå¥åº·çŠ¶æ€åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if self.api_urls:
            api_url = self.api_urls[0]
            if api_health_monitor.is_api_available(api_url):
                health_summary = api_health_monitor.get_health_summary().get(api_url, {})
                success_rate = health_summary.get('success_rate', 1.0)
                
                # æ ¹æ®æˆåŠŸç‡è°ƒæ•´æ‰¹æ¬¡å¤§å°
                if success_rate > 0.95:
                    adaptive_batch_size = self.batch_size  # ä½¿ç”¨æœ€å¤§æ‰¹æ¬¡
                elif success_rate > 0.8:
                    adaptive_batch_size = max(3, self.batch_size - 1)  # ç¨å¾®å‡å°‘
                else:
                    adaptive_batch_size = max(2, self.batch_size - 2)  # æ˜¾è‘—å‡å°‘
            else:
                adaptive_batch_size = 2  # APIä¸å¥åº·æ—¶ä½¿ç”¨æœ€å°æ‰¹æ¬¡
        else:
            adaptive_batch_size = self.batch_size
        
        self.logger.debug(f"è‡ªé€‚åº”æ‰¹æ¬¡å¤§å°: {adaptive_batch_size}")
        
        # åˆ›å»ºæ‰¹æ¬¡
        for i in range(0, len(keywords), adaptive_batch_size):
            batch = keywords[i:i + adaptive_batch_size]
            batches.append(batch)
        
        return batches
    
    def _process_single_batch_optimized(self, batch: List[str]) -> Dict[str, Any]:
        """ä¼˜åŒ–çš„å•æ‰¹æ¬¡å¤„ç†"""
        if not batch or not self.api_client:
            return {}
        
        try:
            # ä½¿ç”¨ä¼˜åŒ–çš„APIå®¢æˆ·ç«¯å¤„ç†æ‰¹æ¬¡
            batch_result = self.api_client.batch_query_keywords(batch, max_retries=2)
            
            # æ›´æ–°APIå¥åº·çŠ¶æ€
            if self.api_urls:
                api_url = self.api_urls[0]
                if batch_result:
                    api_health_monitor.record_success(api_url)
                else:
                    api_health_monitor.record_failure(api_url, "batch_processing_failed")
            
            return batch_result if batch_result else {}
            
        except Exception as e:
            self.logger.error(f"æ‰¹æ¬¡å¤„ç†å¼‚å¸¸: {e}")
            
            # è®°å½•APIå¤±è´¥
            if self.api_urls:
                api_health_monitor.record_failure(self.api_urls[0], str(e))
            
            return {}
    
    def _calculate_optimal_wait_time(self, batch_time: float) -> float:
        """è®¡ç®—æœ€ä¼˜ç­‰å¾…æ—¶é—´"""
        base_interval = max(self.batch_interval, 2.0)
        
        # å¦‚æœæ‰¹æ¬¡å¤„ç†æ—¶é—´å·²ç»å¾ˆé•¿ï¼Œå‡å°‘ç­‰å¾…æ—¶é—´
        if batch_time >= base_interval:
            return 0.5  # æœ€å°é—´éš”ï¼Œé¿å…APIå‹åŠ›
        elif batch_time >= base_interval * 0.8:
            return base_interval - batch_time  # è¡¥è¶³åˆ°åŸºç¡€é—´éš”
        else:
            return base_interval - batch_time  # æ­£å¸¸é—´éš”æ§åˆ¶
    
    def start_async_processing(self):
        """å¯åŠ¨å¼‚æ­¥å¤„ç†æ¨¡å¼"""
        if self.is_running:
            return
        
        self.is_running = True
        self.processing_thread = threading.Thread(target=self._async_processing_worker)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        self.logger.info("ğŸ”„ å¼‚æ­¥å¤„ç†æ¨¡å¼å·²å¯åŠ¨")
    
    def stop_async_processing(self):
        """åœæ­¢å¼‚æ­¥å¤„ç†æ¨¡å¼"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # å‘é€åœæ­¢ä¿¡å·
        self.request_queue.put(None)
        
        # ç­‰å¾…å¤„ç†çº¿ç¨‹ç»“æŸ
        if self.processing_thread:
            self.processing_thread.join(timeout=10)
        
        self.logger.info("ğŸ›‘ å¼‚æ­¥å¤„ç†æ¨¡å¼å·²åœæ­¢")
    
    def _async_processing_worker(self):
        """å¼‚æ­¥å¤„ç†å·¥ä½œçº¿ç¨‹"""
        self.logger.info("ğŸ”§ å¼‚æ­¥å¤„ç†å·¥ä½œçº¿ç¨‹å¯åŠ¨")
        
        try:
            while self.is_running:
                try:
                    # è·å–è¯·æ±‚
                    request = self.request_queue.get(timeout=1)
                    if request is None:  # åœæ­¢ä¿¡å·
                        break
                    
                    keywords, callback = request
                    
                    # å¤„ç†å…³é”®è¯
                    result = self.process_keywords_optimized(keywords)
                    
                    # å›è°ƒç»“æœ
                    if callback:
                        callback(result)
                    else:
                        self.result_queue.put(result)
                    
                    self.request_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    self.logger.error(f"å¼‚æ­¥å¤„ç†å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
                    
        finally:
            self.logger.info("ğŸ”§ å¼‚æ­¥å¤„ç†å·¥ä½œçº¿ç¨‹ç»“æŸ")
    
    def submit_async_request(self, keywords: List[str], callback: Optional[callable] = None):
        """æäº¤å¼‚æ­¥è¯·æ±‚"""
        if not self.is_running:
            self.start_async_processing()
        
        self.request_queue.put((keywords, callback))
    
    def get_async_result(self, timeout: float = None) -> Optional[Dict[str, Any]]:
        """è·å–å¼‚æ­¥å¤„ç†ç»“æœ"""
        try:
            return self.result_queue.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def get_queue_status(self) -> Dict[str, int]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        return {
            'pending_requests': self.request_queue.qsize(),
            'pending_results': self.result_queue.qsize(),
            'is_running': self.is_running
        }
    
    def close(self):
        """å…³é—­å¤„ç†å™¨"""
        self.stop_async_processing()
        
        if self.api_client:
            self.api_client.close()
        
        self.logger.info("ğŸ”’ ä¼˜åŒ–ä¸²è¡Œå¤„ç†å™¨å·²å…³é—­")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

# å…¨å±€å®ä¾‹
_optimized_processor = None

def get_optimized_processor() -> OptimizedSerialProcessor:
    """è·å–å…¨å±€ä¼˜åŒ–å¤„ç†å™¨å®ä¾‹"""
    global _optimized_processor
    
    if _optimized_processor is None:
        _optimized_processor = OptimizedSerialProcessor(
            api_urls=config.keywords_api_urls,
            batch_size=config.keywords_batch_size,
            batch_interval=config.api_request_interval
        )
    
    return _optimized_processor
